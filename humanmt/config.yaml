bert:
  path: 'bert-base-multilingual-cased'

data:
  source: '.en'
  target: '.hyp'
  marking: '.ann'
  raw: 'data/dummy'
  train: 'data/dummy.tok'
  dev: 'data/dummy.tok'

train:
  lr: 0.003
  optimizer: Adam
  batch_size: 32
  epochs: 10
  seed: 42
  model_dir: humanmt
  shuffle: True
  cuda: False
  early_stopping_metric: loss
  overwrite: True
  normalization: tokens


