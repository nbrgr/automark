bert:
  path: 'bert-base-multilingual-cased'

data:
  source: '.en'
  target: '.hyp'
  marking: '.ann'
  raw: 'data/markings'
  train: 'data/markings.tok'
  dev: 'data/markings.tok'

model:
  hidden_dimension: 50
  activation: "tanh"
  freeze_bert: True
  head_bias: False

train:
  lr: 0.00002
  optimizer: Adam
  batch_size: 32
  epochs: 10
  seed: 42
  model_dir: humanmt
  shuffle: True
  cuda: False
  early_stopping_metric: loss
  overwrite: True
  normalization: batch
  bad_weight: 5.0
  validation_freq: 500
  logging_freq: 1
  weighing: 'percentage'
